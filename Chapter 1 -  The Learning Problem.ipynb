{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: The Learning Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Importing Necessary Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercises"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 1.1: Express each of the following tasks in the framework of learning from data by specifying the input space $\\mathcal{X}$, output space $\\mathcal{Y}$, target function $f: \\mathcal{X} \\to \\mathcal{Y}$. and the specifics of the data set that we will learn from.\n",
    "\n",
    "**(a) Medical diagnosis: A patient walks in with a medical history and some symptoms, and you want to identify the problem.**\n",
    "  1. **Input Space $\\mathcal{X}$:** Patient's medical history, symptoms, personal health information, etc.\n",
    "  2. **Output Space $\\mathcal{Y}$:** All possible diseases\n",
    "  3. **Target Function $f: \\mathcal{X} \\to \\mathcal{Y}$:** Ideal formula to identify a patient's problem\n",
    "  4. **Data set:** All available patients' information and their corresponding correct problem diagnostic.\n",
    "\n",
    "**(b) Handwritten digit recognition (for example postal zip code recognition for mail sorting).**\n",
    "  1. **Input Space $\\mathcal{X}$:** handwritten digits (digitalized)\n",
    "  2. **Output Space $\\mathcal{Y}$:** 0-9 digits\n",
    "  3. **Target Function $f: \\mathcal{X} \\to \\mathcal{Y}$:** ideal formula match a handwritten digit to a correct digit\n",
    "  4. **Data set:** handwritten digits and their corresponding correct matches\n",
    "\n",
    "**(c) Determining if an email is spam or not.**\n",
    "  1. **Input Space $\\mathcal{X}$:** every information of an email, e.g. words\n",
    "  2. **Output Space $\\mathcal{Y}$:** yes/no \n",
    "  3. **Target Function $f: \\mathcal{X} \\to \\mathcal{Y}$:** ideal formula to identify whether an email is spam or not\n",
    "  4. **Data set:** Spam and non-spam emails that have been identified by human\n",
    "\n",
    "**(d) Predicting how an electric load varies with price, temperature, and day of the week.**\n",
    "  1. **Input Space $\\mathcal{X}$:** price of electric, temperature, day of the week\n",
    "  2. **Output Space $\\mathcal{Y}$:** electric load\n",
    "  3. **Target Function $f: \\mathcal{X} \\to \\mathcal{Y}$:** ideal function that gives exact electric load for a given price, temperature and day of the week.\n",
    "  4. **Data set:** historical electric load along with corresponding price, temperature and day of the week information.\n",
    "\n",
    "**(e) A problem of interest to you for which there is no analytic solution, but you have data from which to construct an empirical solution.** \n",
    "  1. **Input Space $\\mathcal{X}$:** cat images \n",
    "  2. **Output Space $\\mathcal{Y}$:** types of cats\n",
    "  3. **Target Function $f: \\mathcal{X} \\to \\mathcal{Y}$:** ideal function that gives cat type according to the picture\n",
    "  4. **Data set:** Pictures with cats that have been categorized to various types"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 1.2: Suppose that we use a perceptron to detect spam messages. Let's say that each email message is represented by the frequency of occurrence of keywords, and the output is $+1$ if the message is considered spam.\n",
    "\n",
    "**(a) Can you think of some keywords that will end up with a large positive weight in the perceptron?**\n",
    "- Keywords with a large positive weight: free, cheap, earn, !\n",
    "\n",
    "**(b) How about keywords that will get a negative weight?**\n",
    "- Keywords with a negative weight: person name, hi, the\n",
    "\n",
    "**(c) What para meter in the perceptron directly affects how many borderline messages end up being classified as spam?**\n",
    "- The parameter $b$ in perceptron directly affects how many borderline messages end up being classified as spam. This is because $b$ is the threshold used to classify the emails into spam and non-spam categories."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 1.3: The weight update rule in (1.3) has the nice interpretation that it moves in the direction of classifying $x(t)$ correctly. *[Rule 1.3: $w(t+1)=w(t)+y(t) \\cdot x(t)$]*\n",
    "\n",
    "**(a) Show that $y(t)w^{T}(t)x(t) < 0$. [Hint: $x(t)$ is misclassified by $w(t)$.]**\n",
    "- Given that $x(t)$ is misclassified by $w(t)$, the sign of the dot product $w^{T}(t)x(t)$ is opposite to the label $y(t)$. Possible signs for $y(t)$ are either $+1$ or $-1$.\n",
    "- If $y(t)=+1$ and $x(t)$ is misclassified, then $w^{T}(t)x(t)<0$. Multiplying both sides by $y(t)$ results in: $y(t)w^{T}(t)x(t) < 0$\n",
    "- Similarly, if $y(t)=-1$ and $x(t)$ is misclassified, then $w^{T}(t)x(t)>0$ w T (t)x(t)>0. Multiplying both sides by $y(t)$ yields: $y(t)w^{T}(t)x(t) < 0$\n",
    "\n",
    "**(b) Show that $y(t)w^{T}(t+1)x(t) > y(t)w^{T}(t)x(t)$. [Hint: Use (1.3).]**\n",
    "- From rule 1.3, taking the dot product with $x(t)$ on both sides, we get: $w^{T}(t+1) \\cdot x(t)=w^{T}(t) \\cdot x(t)+y(t) \\cdot x^{T}(t) \\cdot x(t)$\n",
    "- Since $x^{T}(t) \\cdot x(t)$ is the square of the norm of $x(t)$ (always non-negative) and $y(t)w^{T}(t)x(t) < 0$, adding a positive value to $w^{T}(t) \\cdot x(t)$ increases its value:\n",
    "\\begin{align*}\n",
    "y(t)w^T(t+1)x(t) &= y(t)w^{T}(t)x(t) + {y(t)}^{2}x^{T}(t)x(t) \\\\\n",
    "&= y(t)w^{T}(t)x(t) + x^{T}(t)x(t) \\\\\n",
    "&\\gt y(t)w^T(t)x(t) \\\\ \n",
    "\\end{align*}\n",
    "- Notes: \n",
    "- ${y(t)}^{2}$ is always $1$ (because $y(t)$ is either $+1$ or $-1$).\n",
    "- $x^{T}(t)x(t) \\ge 0$, which justifies the inequality.\n",
    "\n",
    "**(c) As far as classifying x(t) is concerned, argue that the move from $w(t)$ to $w(t+1)$ is a move 'in the right direction'.** \n",
    "\n",
    "From part (b), we've demonstrated that the product $y(t)w^T(t+1)x(t)$ is increasing compared to $y(t)w^T(t)x(t)$. We know the misclassification is indicated when $y(t)w^T(t)x(t)<0$. The weight update rule pushes this value towards the positive, aiming to correct the misclassification. If this value becomes positive, then $x(t)$ would be correctly classified by the updated weight. Therefore, the move from $w(t)$ to $w(t+1)$ using rule (1.3) is indeed \"in the right direction\" for classifying $x(t)$.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Exercise 1.3\n",
    "\n",
    "def misclassified(w, x, y):\n",
    "    \"\"\"Check if x is misclassified by w.\"\"\"\n",
    "    return y * w.T @ x < 0\n",
    "\n",
    "def perceptron_update(w, x, y):\n",
    "    \"\"\"Update weights using the perceptron rule.\"\"\"\n",
    "    return w + y * x\n",
    "\n",
    "def main():\n",
    "    # Randomly initialize weights and input x(t)\n",
    "    w_t = np.array([1.0, -1.0])\n",
    "    x_t = np.array([0.5, 1.5])\n",
    "    y_t = 1.0  # Suppose y(t) is 1\n",
    "    \n",
    "    # (a) Check if x(t) is misclassified by w(t)\n",
    "    is_misclassified = misclassified(w_t, x_t, y_t)\n",
    "    print(f\"(a) Is x(t) misclassified by w(t)? {'Yes' if is_misclassified else 'No'}\")\n",
    "    \n",
    "    # (b) Update w(t) to w(t+1) using the perceptron rule\n",
    "    w_t_plus_1 = perceptron_update(w_t, x_t, y_t)\n",
    "    comparison = y_t * w_t_plus_1.T @ x_t > y_t * w_t.T @ x_t\n",
    "    print(f\"(b) After update, is y(t)w(t+1)T*x(t) greater than y(t)w(t)T*x(t)? {'Yes' if comparison else 'No'}\")\n",
    "    \n",
    "    # (c) Check if w(t+1) classifies x(t) correctly, indicating move in the right direction\n",
    "    is_correct_after_update = not misclassified(w_t_plus_1, x_t, y_t)\n",
    "    print(f\"(c) Is the move from w(t) to w(t+1) in the right direction? {'Yes' if is_correct_after_update else 'No'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Exercise 1.4: Let us create our own target function $\\mathcal{f}$ and data set $\\mathcal{D}$ and see how the perceptron learning algorithm works. Take $\\mathcal{d}=2$ so you can visualize the problem, and choose a random line in the plane as your target function, where one side of the line maps to $+1$ and the other maps to $-1$. Choose the inputs $x_n$ of the data set as random points in the plane, and evaluate the target function on each $x_n$ to get the corresponding output $y_n$ · Now, generate a data set of size $20$. Try the perceptron learning algorithm on your data set and see how long it takes to converge and how well the final hypothesis $\\mathcal{g}$ matches your target $\\mathcal{f}$. You can find other ways to play with this experiment in Problem 1.4\n",
    "\n",
    "1. **Generate a Target Function, $f$:** Choose a random line in the $2D$ plane.\n",
    "- Let's pick two random points $A$ and $B$ in the plane to define our line. The equation of the line passing through $A(x_1,y_1)$ and $B(x_2,y_2)$ can be represented as: $y=m \\times x + c$. Note: $m=\\frac{y_2-y_1}{x_2-x_1}$ and $c=y_{1}−m \\times x_{1}$\n",
    "\n",
    "1. **Generate $\\mathcal{D}$:** \n",
    "- Randomly sample $20$ points. For each point $\\left(x,y\\right)$, if $y$ is above the line, label it as $+1$, otherwise label it as $-1$.\n",
    "\n",
    "1. **Run the Perceptron Learning Algorithm:** \n",
    "- Initialize weights $w$ randomly.\n",
    "- Once there are misclassified points, For each point in the dataset, If it's misclassified, update the weights: $w(t+1)=w(t)+y(t) \\cdot x(t)$\n",
    "\n",
    "1. **Compare the Hypothesis $g$ to the Target Function $f$:**\n",
    "- The final weights $w$ will give the hypothesis $g$. You can then visualize the line defined by $g$ and compare it to $f$.\n",
    "\n",
    "\n",
    "*Running the code below will generate a visualization comparing the target function $f$ (in red) and the learned hypothesis $g$ (in green). It will also print the number of iterations required for convergence. This provides a demonstration of the convergence speed of the algorithm and the alignment between the learned hypothesis and the target function. As a supplementary answer to this exercise, the convergence speed of the perceptron learning algorithm is generally fast. In this specific run, it took $X$ iterations (where $X$ will be the printed value) to converge. Visually, while the coefficients of the learned hypothesis $g$ might differ from the target function $f$, they align closely within the data range, which confirms the capability of the perceptron learning algorithm to approximate the target function given linearly separable data.*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.4\n",
    "\n",
    "def random_line():\n",
    "    \"\"\"Generate a random line in the plane and return its slope and intercept.\"\"\"\n",
    "    A, B = np.random.uniform(-1, 1, (2, 2))\n",
    "    slope = (B[1] - A[1]) / (B[0] - A[0] + 1e-15)  # Avoid division by zero\n",
    "    intercept = A[1] - slope * A[0]\n",
    "    return slope, intercept\n",
    "\n",
    "def generate_dataset(slope, intercept, N=20):\n",
    "    \"\"\"Generate a dataset of N points and label them based on a line defined by slope and intercept.\"\"\"\n",
    "    X = np.random.uniform(-1, 1, (N, 2))\n",
    "    Y = np.sign(X[:, 1] - (slope * X[:, 0] + intercept))\n",
    "    return X, Y\n",
    "\n",
    "def perceptron(X, Y):\n",
    "    \"\"\"Perceptron Learning Algorithm.\"\"\"\n",
    "    w = np.random.rand(3)\n",
    "    X_augmented = np.column_stack((np.ones(X.shape[0]), X))\n",
    "    \n",
    "    while True:\n",
    "        predictions = np.sign(X_augmented @ w)\n",
    "        misclassified = np.where(predictions != Y)[0]\n",
    "        \n",
    "        if len(misclassified) == 0:\n",
    "            break\n",
    "            \n",
    "        random_idx = np.random.choice(misclassified)\n",
    "        w += Y[random_idx] * X_augmented[random_idx]\n",
    "        \n",
    "    return w\n",
    "\n",
    "def visualize(X, Y, slope, intercept, weights):\n",
    "    \"\"\"Visualize the data points, target function, and the perceptron's boundary.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot points for each class\n",
    "    plt.scatter(X[Y == 1][:, 0], X[Y == 1][:, 1], c='blue', edgecolors='k', label=\"Class +1\")\n",
    "    plt.scatter(X[Y == -1][:, 0], X[Y == -1][:, 1], c='red', edgecolors='k', label=\"Class -1\")\n",
    "    \n",
    "    x_range = np.linspace(-1, 1, 100)\n",
    "    plt.plot(x_range, slope * x_range + intercept, '-r', label=\"Target function f\")\n",
    "    plt.plot(x_range, -(weights[1] * x_range + weights[0]) / (weights[2] + 1e-15), '-g', label=\"Hypothesis g\")\n",
    "    \n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.title(\"Perceptron Learning Algorithm Visualization\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    slope, intercept = random_line()\n",
    "    X, Y = generate_dataset(slope, intercept)\n",
    "    weights = perceptron(X, Y)\n",
    "    visualize(X, Y, slope, intercept, weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.5: Which of the following problems are more suited for the learning approach and which are more suited for the design approach?\n",
    "\n",
    "**(a) Determining the age at which a particular medical test should be performed**\n",
    "- Learning\n",
    " \n",
    "**(b) Classifying numbers into primes and non-primes**\n",
    "- Design\n",
    "\n",
    "**(c) Detecting potential fraud in cred it card charges**\n",
    "- Learning\n",
    "\n",
    "**(d) Determining the time it would take a falling object to hit the ground**\n",
    "- Design\n",
    "\n",
    "**(e) Determining the optimal cycle for traffic lights in a busy intersection**\n",
    "-  Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Exercise 1.6: For each of the following tasks, identify which type of learning is involved (supervised, reinforcement, or unsupervised) and the training data to be used. If a task can fit more than one type, explain how and describe the training data for each type.\n",
    "\n",
    "**(a) Recommending a book to a user in an online bookstore**\n",
    "- Supervised Learning\n",
    "\n",
    "**(b) Playing tic tac toe**\n",
    "- Reinforcement Learning\n",
    "\n",
    "**(c) Categorizing movies into different types**\n",
    "- Unsupervised Learning\n",
    "\n",
    "**(d) Learn ing to play music**\n",
    "- Learning to play music\n",
    "    * If learn by yourself, it's unsupervised learning\n",
    "    * If learn from a teacher, it's supervised learning\n",
    "    * If learn by yourself but with someone to tell you if your music is good or not, it's reinforcement learning.  \n",
    "\n",
    "**(e) Credit limit: Deciding the maximum allowed debt for each bank customer**\n",
    "- Supervised Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Exercise 1.7: For each of the following learning scenarios in the above problem, evaluate the performance of $g$ on the three points in $\\mathcal{X}$ outside $\\mathcal{D}$. To measure the performance, compute how many of the $8$ possible target functions agree with $g$ on all three points, on two of them, on one of them, and on none of them.\n",
    "\n",
    "**(a) $\\mathcal{H}$ has only two hypotheses, one that always returns $'\\bullet'$ and one that always returns $'\\circ'$. The learning algorithm picks the hypothesis that matches the data set the most.**\n",
    "- The learning algorithm will pick the final hypothesis that always returns 1. \n",
    "    * 1 out of 8 $f$ agrees with $g$ on all three points; 3 $f$ agree with $g$ on two of the points; 3 $f$ agree with $g$ on one of the points, 1 $f$ agrees with none of the points. \n",
    "\n",
    "**(b) The same $\\mathcal{H}$, but the learning algorithm now picks the hypothesis that matches the data set the least.**\n",
    "- The learning algorithm will pick the final hypothesis that always returns 0. \n",
    "    * 1 out of 8 $f$ agrees with $g$ on all three points; 3 $f$ agree with $g$ on two of the points; 3 $f$ agree with $g$ on one of the points, 1 $f$ agrees with none of the points.\n",
    "\n",
    "**(c) $\\mathcal{H}=\\left\\{XOR\\right\\}$ (only one hypothesis which is always picked), where $XOR$ is defined by $XOR\\left( x \\right)=\\bullet$ if the number of $1's$ in $x$ is odd and $XOR\\left( x \\right)=\\circ$ if the number is even.**\n",
    "- The learning algorithm will pick the final hypothesis $XOR$. \n",
    "    * 1 out of 8 $f$ agrees with $g$ on all three points; 3 $f$ agree with $g$ on two of the points; 3 $f$ agree with $g$ on one of the points, 1 $f$ agrees with none of the points.\n",
    "\n",
    "\n",
    "**(d) $\\mathcal{H}$ contains all possible hypotheses (all Boolean functions on three variables), and the learning algorithm picks the hypothesis that agrees with all training examples, but otherwise disagrees the most with the $XOR$.**\n",
    "- The learning algorithm will pick the final hypothesis $f_7$. \n",
    "    * 1 out of 8 $f$ agrees with $g$ on all three points; 3 $f$ agree with $g$ on two of the points; 3 $f$ agree with $g$ on one of the points, 1 $f$ agrees with none of the points.\n",
    "  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# All possible points in X\n",
    "points = list(product([0, 1], repeat=3))\n",
    "\n",
    "# For demonstration purposes, let's assume D has 5 random points with corresponding outputs\n",
    "D = {\n",
    "    (0, 0, 0): '⚫',\n",
    "    (0, 0, 1): '⚪',\n",
    "    (0, 1, 0): '⚫',\n",
    "    (0, 1, 1): '⚪',\n",
    "    (1, 0, 0): '⚫'\n",
    "}\n",
    "\n",
    "def score(g, test_points):\n",
    "    \"\"\"Evaluate how many of the 8 possible target functions agree with g on the test points.\"\"\"\n",
    "    scores = [0] * 4  # Agree on all, two, one, none\n",
    "    for target in product(['⚫', '⚪'], repeat=3):\n",
    "        match_count = sum(g[point] == value for point, value in zip(test_points, target))\n",
    "        scores[match_count] += 1\n",
    "    return scores\n",
    "\n",
    "# (a) H has only two hypotheses\n",
    "hypotheses_a_b = [{point: '⚫' for point in points}, {point: '⚪' for point in points}]\n",
    "matches = [sum(h[point] == D[point] for point in D) for h in hypotheses_a_b]\n",
    "g_a = hypotheses_a_b[matches.index(max(matches))]\n",
    "g_b = hypotheses_a_b[matches.index(min(matches))]\n",
    "\n",
    "# (c) H = {XOR}\n",
    "g_c = {point: '⚫' if sum(point) % 2 else '⚪' for point in points}\n",
    "\n",
    "# (d) H contains all possible hypotheses\n",
    "xor = lambda x: '⚫' if sum(x) % 2 else '⚪'\n",
    "g_d = {point: D[point] if point in D else ('⚪' if xor(point) == '⚫' else '⚫') for point in points}\n",
    "\n",
    "test_points = [point for point in points if point not in D]\n",
    "results = {\n",
    "    \"a\": score(g_a, test_points),\n",
    "    \"b\": score(g_b, test_points),\n",
    "    \"c\": score(g_c, test_points),\n",
    "    \"d\": score(g_d, test_points)\n",
    "}\n",
    "\n",
    "print(results)\n",
    "\n",
    "def visualize(g, ax, title):\n",
    "    \"\"\"Visualize the classification of points using a 3D scatter plot.\"\"\"\n",
    "    colors = {'⚫': 'black', '⚪': 'white'}\n",
    "    \n",
    "    for point, color in g.items():\n",
    "        ax.scatter(point[0], point[1], point[2], c=colors[color], s=100, edgecolors='k', depthshade=False)\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title(title)\n",
    "\n",
    "# Create a single figure with 4 subplots for each scenario\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax1 = fig.add_subplot(221, projection='3d')\n",
    "ax2 = fig.add_subplot(222, projection='3d')\n",
    "ax3 = fig.add_subplot(223, projection='3d')\n",
    "ax4 = fig.add_subplot(224, projection='3d')\n",
    "\n",
    "# Visualize each hypothesis\n",
    "visualize(g_a, ax1, \"Scenario (a)\")\n",
    "visualize(g_b, ax2, \"Scenario (b)\")\n",
    "visualize(g_c, ax3, \"Scenario (c)\")\n",
    "visualize(g_d, ax4, \"Scenario (d)\")\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 1.8: If $\\mu=0.9$, what is the probability that a sample of $10$ marbles will have $\\nu\\le 0.1$? *[Hints: 1. Use binomial distribution. 2. The answer is a very small number.]*\n",
    "\n",
    "In a sample of 10 marbles, for the fraction $\\nu$ of red marbles to be $\\nu \\le 0.1$, we must have at most one red marbles. \n",
    "\n",
    "\\begin{align*}\n",
    "P(number\\;of\\;red \\le 1) &= P(red = 0) + P(red = 1) \\\\\n",
    "&= (1-\\mu)^{10} + \\mu (1-\\mu)^9\\\\\n",
    "&= (1-\\mu)^9\\\\\n",
    "&= 1.0e-9\n",
    "\\end{align*}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 1.9: If $\\mu=0.9$, use the Hoeffding Inequality to bound the probability that a sample of $10$ marbles will have $\\nu\\le 0.1$ and compare the answer to the previous exercise.\n",
    "\n",
    "We have $\\mu=0.9$, $N=10$, and want $\\nu \\le 0.1$, i.e. $|\\mu - \\nu| = \\mu - \\nu \\ge 0.9 - 0.1 = 0.8$. Let's pick $\\epsilon = 0.7$, then according to Hoeffding Inequity, we have\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\nu \\le 0.1) &= P(\\mu - \\nu \\ge 0.8)\\\\\n",
    "&= P(|\\mu - \\nu| \\ge 0.8) \\\\\n",
    "&\\le P(|\\mu - \\nu| \\gt 0.7) \\\\\n",
    "&= P(|\\mu - \\nu| \\gt \\epsilon) \\\\\n",
    "&\\le 2e^{-2\\epsilon^2N}\\\\\n",
    "&\\approx 0.0001109032\n",
    "\\end{align*}\n",
    "\n",
    "This is an upper bound of the probability from pervious problem and is much larger than the calculated probability.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.10: Here is an experiment that illustrates the difference between a single bin and multiple bins. Run a computer simulation for flipping $1,000$ fair coins. Flip each coin independently $10$ times. Let's focus on $3$ coins as follows: $c_1$ is the first coin flipped; $c_{rand}$ is a coin you choose at random ; $c_{min}$ is the coin that had the minimum frequency of heads (pick the earlier one in case of a tie). Let $v_1$, $v_{rand}$ and $v_{min}$ be the fraction of heads you obtain for the respective three coins.\n",
    "\n",
    "**(a) What is $\\mu$ for the th ree coins selected?**\n",
    "- The $\\mu$ for the three coins are all $0.5$ since the coins are fair.\n",
    "\n",
    "**(b) Repeat this entire experiment a large number of times (e.g., $100,000$ runs of the entire experiment) to get several instances of $v_1$, $v_{rand}$ and $v_{min}$ and plot the histograms of the distributions of $v_1$, $v_{rand}$ and $v_{min}$· Notice that which coins end up being $c_{rand}$ and $c_{min}$ may differ from one run to another.**\n",
    "- Check the code's output.\n",
    "\n",
    "**(c) Using (b), plot estimates for $\\mathbb{P}\\left[\\left|\\nu-\\mu\\right|\\gt\\epsilon\\right]$ as a function of $\\epsilon$, together with the Hoeffding bound $2\\mathcal{e}^{-2\\epsilon^{2}N}$ (on the same graph).**\n",
    "- Check the code's output.\n",
    "\n",
    "**(d) To answer this, we can look at the graph we plotted in part (c). The coins that obey the Hoeffding bound will have their estimated probabilities $\\mathbb{P}\\left[ \\left| \\nu - \\mu\\ \\right| \\gt \\epsilon \\right]$ below or equal to the Hoeffding bound across all $\\epsilon$.**\n",
    "\n",
    "Based on our simulation: \n",
    "1. **$v_{1}$ (first coin flipped):** This should obey the Hoeffding bound. The reason being that the probability of any single coin (like the first one) showing a fraction of heads that deviates significantly from its expectation is bounded by Hoeffding. In essence, the result for this coin is derived from a single bin of the Hoeffding inequality.\n",
    "2. **$v_{rand}$ (random coin):** This should also obey the Hoeffding bound for similar reasons as $v_{1}$. Even though we're picking a coin at random, the probability for that specific coin deviating from its expectation is still bounded by the Hoeffding inequality.\n",
    "3. **$v_{min}$ (coin with the minimum fraction of heads):** This is the interesting case and might not obey the Hoeffding bound. The reason is that when we pick the coin with the minimum fraction of heads, we're effectively looking at the \"worst-case\" scenario out of the 1000 coins. By repeatedly doing this across our simulation runs, we're amplifying any deviations from the expected fraction of heads. This procedure touches upon the concept of \"multiple bins\" in the Hoeffding inequality. Essentially, each coin represents a separate bin, and by selecting the worst-case bin repeatedly, the Hoeffding bound for a single bin doesn't necessarily apply.\n",
    "\n",
    "In summary, both $v_{1}$ and $v_{rand}$ are expected to obey the Hoeffding bound, while $v_{min}$ might not.\n",
    "\n",
    "This code, we will observe how the probability of $\\left| \\nu - \\mu\\ \\right| \\gt \\epsilon$ compares to the Hoeffding bound for each coin over a range of $\\epsilon$ values. If the observed probability consistently exceeds the Hoeffding bound for a particular coin, that indicates the coin doesn't obey the inequality.\n",
    "\n",
    "(e) The figure illustrates the concept of multiple bins by visualizing different hypotheses $h$. Each vessel (or bin) contains green and red marbles. The green marbles can be thought of as successful predictions or correct classifications by a hypothesis, while the red marbles can be thought of as errors or misclassifications.\n",
    "\n",
    "Now, let's relate this to the coin experiment:\n",
    "\n",
    "1. **Single Bin:** The scenarios with $v_{1}$ and $v_{rand}$ can be related to looking at a single bin in isolation. For both these cases, even if we repeated the experiment multiple times, we're essentially analyzing the results of one bin at a time. This is why they both obey the Hoeffding bound: we're not doing anything special to select the bin, so the inherent randomness of the coin flips should be bounded by Hoeffding's inequality.\n",
    "\n",
    "2. **Multiple Bins:** $v_{min}$ is a different case. Out of the 1000 coins (or bins), we're always picking the coin that had the minimum frequency of heads. In the context of the figure, this is like always selecting the vessel that has the highest number of red marbles (errors). So even if by pure chance a few coins had an unusually low number of heads (like a vessel having an unusually high number of red marbles), by always selecting $v_{min}$, we're magnifying this rare event. This is why $v_{min}$ might not obey the Hoeffding bound: we're no longer looking at the randomness of a single bin, but rather at the extremity across multiple bins.\n",
    "\n",
    "In conclusion, the figure visually captures the difference between evaluating the performance of a single hypothesis in isolation versus cherry-picking the worst-performing hypothesis after evaluating many. The latter is akin to $v_{min}$, and it demonstrates why we need to be cautious when selecting hypotheses based on their performance on a finite sample: the worst (or best) performer might not generalize well to new data, and the guarantees provided by tools like the Hoeffding bound might not hold when considering multiple hypotheses (or bins) at once.\n",
    "\n",
    "The code below hypothetical code that would demonstrate the effects of selecting the best/worst hypothesis (akin to selecting $v_{min}$) from multiple hypotheses using the analogy of the bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.10 (a) \n",
    "num_runs = 100000\n",
    "num_coins = 1000\n",
    "num_flips = 10\n",
    "\n",
    "# Exercise 1.10 (b) \n",
    "def flip_coins(num_coins, num_flips):\n",
    "    # 1 represents heads and 0 represents tails\n",
    "    return np.random.binomial(1, 0.5, (num_coins, num_flips))\n",
    "\n",
    "v_1_list = []\n",
    "v_rand_list = []\n",
    "v_min_list = []\n",
    "\n",
    "for _ in range(num_runs):\n",
    "    results = flip_coins(num_coins, num_flips)\n",
    "    v = np.mean(results, axis=1)  # Fraction of heads for each coin\n",
    "    \n",
    "    v_1 = v[0]\n",
    "    v_rand = np.random.choice(v)\n",
    "    v_min = np.min(v)\n",
    "    \n",
    "    v_1_list.append(v_1)\n",
    "    v_rand_list.append(v_rand)\n",
    "    v_min_list.append(v_min)\n",
    "\n",
    "# Plot histograms\n",
    "plt.hist(v_1_list, bins=np.linspace(0, 1, 11), alpha=0.5, label='$v_1$')\n",
    "plt.hist(v_rand_list, bins=np.linspace(0, 1, 11), alpha=0.5, label='$v_{rand}$')\n",
    "plt.hist(v_min_list, bins=np.linspace(0, 1, 11), alpha=0.5, label='$v_{min}$')\n",
    "plt.legend()\n",
    "plt.title(\"Histograms of $v_1$, $v_{rand}$, and $v_{min}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.10 (c)\n",
    "epsilons = np.linspace(0, 0.5, 100)\n",
    "mu = 0.5\n",
    "N = 10  # number of flips per coin\n",
    "\n",
    "# Calculate the probabilities\n",
    "prob_v_1 = [np.mean(np.abs(np.array(v_1_list) - mu) > eps) for eps in epsilons]\n",
    "prob_v_rand = [np.mean(np.abs(np.array(v_rand_list) - mu) > eps) for eps in epsilons]\n",
    "prob_v_min = [np.mean(np.abs(np.array(v_min_list) - mu) > eps) for eps in epsilons]\n",
    "\n",
    "# Calculate the Hoeffding bound\n",
    "hoeffding_bound = [2 * np.exp(-2 * eps**2 * N) for eps in epsilons]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(epsilons, prob_v_1, label=\"$v_1$\", color=\"blue\")\n",
    "plt.plot(epsilons, prob_v_rand, label=\"$v_{rand}$\", color=\"green\")\n",
    "plt.plot(epsilons, prob_v_min, label=\"$v_{min}$\", color=\"red\")\n",
    "plt.plot(epsilons, hoeffding_bound, label=\"Hoeffding Bound\", linestyle=\"--\", color=\"black\")\n",
    "plt.xlabel(\"$\\epsilon$\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.title(\"Probabilities and Hoeffding Bound versus $\\epsilon$\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Exercise 1.10 (d)\n",
    "# Number of experiments\n",
    "num_experiments = 100000\n",
    "\n",
    "# Number of flips per coin\n",
    "N = 10\n",
    "\n",
    "# Number of coins\n",
    "M = 1000\n",
    "\n",
    "# True probability of heads\n",
    "mu = 0.5\n",
    "\n",
    "v_1_list = []\n",
    "v_rand_list = []\n",
    "v_min_list = []\n",
    "\n",
    "for _ in range(num_experiments):\n",
    "    coin_results = np.random.binomial(N, mu, M) / N\n",
    "    v_1_list.append(coin_results[0])\n",
    "    v_rand_list.append(coin_results[np.random.randint(0, M)])\n",
    "    v_min_list.append(coin_results.min())\n",
    "\n",
    "def exceeds_hoeffding_bound(v_list, epsilon):\n",
    "    count = sum(1 for v in v_list if abs(v - mu) > epsilon)\n",
    "    observed_probability = count / num_experiments\n",
    "    hoeffding_bound = 2 * np.exp(-2 * epsilon**2 * N)\n",
    "    return observed_probability, hoeffding_bound\n",
    "\n",
    "epsilons = np.arange(0.01, 0.5, 0.01)\n",
    "observed_1_probs = []\n",
    "observed_rand_probs = []\n",
    "observed_min_probs = []\n",
    "hoeffding_bounds = []\n",
    "\n",
    "for epsilon in epsilons:\n",
    "    observed_1, bound = exceeds_hoeffding_bound(v_1_list, epsilon)\n",
    "    observed_rand, _ = exceeds_hoeffding_bound(v_rand_list, epsilon)\n",
    "    observed_min, _ = exceeds_hoeffding_bound(v_min_list, epsilon)\n",
    "    \n",
    "    observed_1_probs.append(observed_1)\n",
    "    observed_rand_probs.append(observed_rand)\n",
    "    observed_min_probs.append(observed_min)\n",
    "    hoeffding_bounds.append(bound)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(epsilons, observed_1_probs, label=\"$v_{1} Observed$\", color='blue')\n",
    "plt.plot(epsilons, observed_rand_probs, label=\"$v_{rand} Observed$\", color='green')\n",
    "plt.plot(epsilons, observed_min_probs, label=\"$v_{min} Observed$\", color='red')\n",
    "plt.plot(epsilons, hoeffding_bounds, label='Hoeffding Bound', linestyle='--', color='black')\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Comparison of Observed Probabilities and Hoeffding Bound')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Exercise 1.10 (e)\n",
    "# Number of hypotheses (bins)\n",
    "M = 1000\n",
    "\n",
    "# Number of samples for each hypothesis\n",
    "N = 10\n",
    "\n",
    "# Number of experiments\n",
    "num_experiments = 100000\n",
    "\n",
    "# Assume red marble (error) occurs with probability 0.5\n",
    "mu = 0.5\n",
    "\n",
    "# Store the errors for the worst hypothesis in each experiment\n",
    "worst_errors = []\n",
    "\n",
    "for _ in range(num_experiments):\n",
    "    # Simulate the results for M hypotheses\n",
    "    errors = [np.mean(np.random.choice([0, 1], N)) for _ in range(M)]\n",
    "    \n",
    "    # Select the worst hypothesis (max error)\n",
    "    worst_error = max(errors)\n",
    "    worst_errors.append(worst_error)\n",
    "\n",
    "# Plot histogram of errors for the worst hypothesis\n",
    "plt.hist(worst_errors, bins=20, alpha=0.7, label=\"Worst Hypothesis Errors\")\n",
    "plt.axvline(mu, color='red', linestyle='dashed', linewidth=1, label=\"Expected Error (mu)\")\n",
    "plt.legend()\n",
    "plt.title(\"Distribution of Errors for the Worst Hypothesis\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.11: \n",
    "#### We are given a data set $\\mathcal{D}$ of $25$ training examples from an unknown target function $\\mathcal{f}:\\mathcal{X}\\to \\mathcal{Y}$, where $\\mathcal{X}=\\mathbb{R}$ and $\\mathcal{Y}=\\left\\{ -1,+1 \\right\\}$. To learn $\\mathcal{f}$, we use a simple hypothesis set $\\mathcal{H}=\\left\\{ h_{1},h_{2} \\right\\}$ where $h_{1}$ is the constant function and $h_{2}$ is the constant $-1$.\n",
    "#### We consider two learning algorithms, S (smart) a n d (crazy). S chooses the hypothesis that agrees the most with $\\mathcal{D}$ and C chooses the other hypothesis deliberately. Let us see how these algorithms perform out of sample from the deterministic and probabilistic points of view. Assume in the probabilistic view that there is a probability distribution on $\\mathcal{X}$, and let $\\mathbb{P}\\left[\\mathcal{f\\left(\\mathrm{x}\\right)=+1}\\right]=p$.\n",
    "\n",
    "**(a) Can S prod uce a hypothesis that is guaranteed to perform better than random on any point outside $\\mathcal{D}$?**\n",
    "- S can not produce a hypothesis that is guaranteed to perform better than random on any point outside $\\mathcal{D}$. \n",
    "    * If $f$ has 25 $+1$ on $\\mathcal{D}$ but $-1$ on all other points in $\\mathcal{X}$, $S$ will choose the hypothesis $h_1$, which will not match $f$ outside $\\mathcal{D}$ at all. On the other hand, a random function will have $+1$ and $-1$ 50/50, and it matches $f$ half of time, which is better than the function produced by $S$.\n",
    "\n",
    "**(b) Assume for the rest of the exercise that all the examples in $\\mathcal{D}$ have $y_n=+1$. Is it possible that the hypothesis that C produces turns out to be better than the hypothesis that S produces?**\n",
    "- It is possible that $C$ produces a better hypothesis than $S$ produces. See the example above.\n",
    "\n",
    "**(c) If $p=0.9$, what is the probability that S will produce a better hypothesis than C?**\n",
    "- If every point in $\\mathcal{D}$ has 1, then $S$ will choose $h_1$ and $C$ will choose $h_2$. So outside of $\\mathcal{D}$, $h_1$ will have 90% chance to match with $f$, while $h_2$ will have only 10% chance. $S$ will always produce a better hypothesis than $C$. \n",
    "\n",
    "**(d) Is there any value of $p$ for which it is more likely than not that C will produce a better hypothesis than S?**\n",
    "- From previous problem, we can see that when $p \\lt 0.5$, $C$ will produce a better hypothesis than $S$. Since $C$ always produce $h_2$, which will match $f$ better than $h_1$ if $p \\lt 0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Exercise 1.12: A friend comes to you with a learning problem . She says the target function is completely unknown, but she has $4,000$ data points. She is willing to pay you to solve her problem and produce for her a $g$ which approximates $f$. What is the best that you can promise her among the following:\n",
    "\n",
    "1. (a) After learn ing you will provide her with a $g$ that you will guarantee approximates $f$ well out of sample.\n",
    "2. (b) After learning you will provide her with a $g$, and with high probability the $g$ which you produce will approximate $f$ well out of sample.\n",
    "3. (c) One of two things will happen.\n",
    "    1. (i) You will produce a hypothesis $g$;\n",
    "    2. (ii) You will declare that you failed.\n",
    "    If you do return a hypothesis $g$, then with high probability the $g$ which you produce will approximate $f$ well out of sample.\n",
    "\n",
    "#### Answer:\n",
    "1. **(a) Guaranteeing approximation out of sample:** Making such a guarantee without any knowledge about the complexity of the target function $f$ or the nature of the data is perilous. If $f$ is complex or the data is noisy, our hypothesis $fg$ might overfit to the $4,000$ data points and perform poorly out-of-sample. Without any information about $f$, it's risky to promise a guarantee.\n",
    "\n",
    "2. **(b) High probability of good out-of-sample approximation:** This is a more measured approach and is often used in the context of machine learning. Through techniques such as cross-validation or theoretical bounds like the VC-dimension, we can estimate the out-of-sample error and say that with high probability, our $g$ will approximate $f$ well. However, \"high probability\" doesn't mean \"guaranteed\", and this is where the uncertainty lies.\n",
    "\n",
    "3. **(c) Two possible outcomes – producing a hypothesis or declaring failure:** This is the most cautious approach. If during the learning process we find that our models aren't fitting the data well, or if validation metrics suggest poor generalization, we can opt to declare that we failed. On the other hand, if our models fit the data well and validation suggests good generalization, we can provide the hypothesis $g$ with a statement that there's a high probability it will work well out-of-sample. This approach provides a safeguard against being overly optimistic about the model's performance.\n",
    "\n",
    "**Conclusion:** The best promise, given the limited information about $f$, would be option (c). This approach allows us to be honest about situations where a good $g$ might not be achievable, while still offering a solution when it appears promising. It's a balance between optimism (finding a good $g$) and realism (acknowledging when the task might be too challenging given the data).\n",
    "\n",
    "_**Note:** Given the Hoeffding inequality's implications, the most aligned promise to make would be option (b). The Hoeffding inequality itself provides the foundation for saying that with high probability, our learned hypothesis will generalize well to new data, based on its performance on the given data. However, the caveat is the assumption that our data is i.i.d. and that the hypothesis set isn't overly complex. Option (c) offers a backup plan in cases where we might doubt the validity of the assumptions (like i.i.d. data) or when other metrics suggest overfitting. But at its core, the confidence provided by the Hoeffding inequality most directly supports the promise in option (b)._"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 1.13: Consider the bin model for a hypothesis $h$ that makes an error with probability $\\mu$ in approximating a deterministic target function $f$ (both $h$ and $f$ are binary functions). If we use the same $h$ to approximate a noisy version of $f$ given by $P\\left(y|\\mathrm{x}\\right)=\\begin{cases}\\begin{matrix} \\lambda & y=f\\left(\\mathrm{x}\\right)),\\\\ 1-\\lambda & y\\neq f\\left(\\mathrm{x}\\right)).\\end{matrix}\\end{cases}$\n",
    "\n",
    "**(a) What is the probability of error that $h$ makes in approximating $y$?**\n",
    "There are two scenarios to consider:\n",
    "\n",
    "1. $h$ agrees with $f$, which happens with probability $1-\\mu$ but then the noisy target $y$ disagrees with $f$, which happens with probability $1-\\lambda$.\n",
    "2. $h$ disagrees with $f$, which happens with probability $\\mu$ and then the noisy target $y$ agrees with $f$, which happens with probability $\\lambda$.\n",
    "- Thus, the probability of error is given by: $P_{error}=\\left( 1-\\mu \\right)\\left( 1-\\lambda \\right)+\\mu\\lambda$\n",
    "\n",
    "\n",
    "**(b) At what value of $\\lambda$ will the performance of $h$ be independent of $\\mu$? _[Hint: The noisy target will look completely random.]_**\n",
    "\n",
    "- For $h$to be independent of $\\mu$, the error rate should be the same regardless of whether $h$ agrees with $f$ or not. This means that the target $y$ looks completely random, so the error rate of $h$ would be $0,5$ (since there's a 50% chance of being correct or incorrect for a completely random target).\n",
    "\n",
    "- Setting $P_{error}=0.5$: $\\left( 1-\\mu \\right)\\left( 1-\\lambda \\right)+\\mu\\lambda=0.5$\n",
    "    * If $y$ is completely random, $\\lambda=0.5$ and $1-\\lambda=0.5$\n",
    "\n",
    "- This implies that the noisy target $y$ agrees with $f$ $50%$ of the time and disagrees $50%$ of the time, making it completely random and independent of $h$. Thus, the value of $\\lambda$ for which the performance of $h$ is independent of $\\mu$ is $\\lambda=0.5$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Problems"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Problem 1.1\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\text{1st ball is black}) &= P(\\text{1st ball is black}|\\text{picked black,black  bag})P(\\text{picked black,black bag}) \\\\\n",
    "&+ P(\\text{1st ball is black}|\\text{picked black,white  bag})P(\\text{picked black,white bag})\\\\\n",
    "&= 1.0*0.5 + 0.5 * 0.5\\\\\n",
    "&= 0.75\\\\\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\text{picked black,black bag}|\\text{1st ball is black}) &= \\frac{P(\\text{picked  black,black bag and 1st ball is black})}{P(\\text{1st ball is black})} \\\\\n",
    "&= \\frac{P(\\text{1st ball is black}|\\text{picked black,black bag})P(\\text{picked black,black bag})}{P(\\text{1st ball is black})}\\\\\n",
    "&= \\frac{1.0*0.5}{0.75}\\\\\n",
    "&= \\frac{2}{3}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\text{picked black,white bag}|\\text{1st ball is black}) &= \\frac{1}{3}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Now we can compute the probability that the second ball is also black:\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\text{2nd ball is black}) &= P(\\text{2nd ball is black}|\\text{picked b-b bag}|\\text{1st ball is black})*P(\\text{picked b-b bag}|\\text{1st ball is black}) \\\\\n",
    "&+ P(\\text{2nd ball is black}|\\text{picked b-w bag}|\\text{1st ball is black})*P(\\text{picked b-w bag}|\\text{1st ball is black})\\\\\n",
    "&= 1.0*\\frac{2}{3} + 0*\\frac{1}{3}\\\\\n",
    "&= \\frac{2}{3}\n",
    "\\end{align*}\n",
    "\n",
    "#### Problem 1.2\n",
    "\n",
    "1. (a)\n",
    "\n",
    "for $h(x) =1$, we need to have $w^Tx \\gt 0$, and for $h(x) = -1$, we need to have $w^Tx \\lt 0$. The line separate the two regions has $w^Tx = w_0 + w_1 x_1 + w_2 x_2 = 0$, compare with $x_2 = ax_1 + b$, we have $ a = -\\frac{w_1}{w_2}$ and $b =  -\\frac{w_0}{w_2}$.\n",
    "\n",
    "1. (b) The pictures for the cases $w=[1,2,3]^T$ and $w=-[1,2,3]^T$ should be be same according to the formula above.\n",
    "\n",
    "#### Problem 1.3\n",
    "\n",
    "\n",
    "1. (a) If $w^{*}$ is the optimal set of weights that separate the data, then for every $x_n$ in the data set $\\mathcal{D}$, $w^{*T}x_n$ has the same sign as $y_n$, which means $y_n(w^{*T}x_n) \\gt 0$. This implies $\\rho = min_{1\\le n\\le N}y_n(w^{*T}x_n) \\gt 0$.\n",
    "\n",
    "\n",
    "1. (a) Let's use induction to prove this.\n",
    "  * When $t=1$, we have $w^T(t-1)w^* + \\rho = w^T(0)w^* + \\rho = \\rho$, while $w(t)=w(1) = w(0) + y_ix_i = y_ix_i$ for some $i$. \n",
    "  \n",
    "  So $w^T(t)w^* = (y_ix_i)^Tw^* = y_ix_i^Tw^* = y_iw^{*T}x_i$. Here we use the fact that $y_i \\in {-1,1}$ and $x_i^Tw^*$ is a scalar. By definition of $\\rho$, we have $y_iw^{*T}x_i \\ge \\rho$. Thus the inequation is valid at $t=1$.\n",
    "  \n",
    "  \n",
    "  * Suppose the inequation is valid at $t$, let's prove that it's still valid at $t+1$. And $w(t+1)=w(t)+y_ix_i$ for some $i$. Then\n",
    "  \n",
    "\\begin{align*}\n",
    "w^T (t+1)w^* &= w^T(t)w^* + y_ix_i^Tw^* \\\\\n",
    "&\\ge w^T(t-1)w^* + \\rho + y_ix_i^Tw^*  \\\\\n",
    "&= \\left(w^T(t-1) + y_ix_i^T\\right)w^* + \\rho \\\\\n",
    "&= w^T(t)w^* + \\rho\\\\\n",
    "\\end{align*}\n",
    "  \n",
    "  This finishes the proof.\n",
    "  \n",
    "  It's easy to see that $w^T(t)w^* \\ge w^T(t-1)w^* + \\rho \\ge w^T(t-2)w^* + 2\\rho \\ge \\dots \\ge t\\rho$.\n",
    "  \n",
    "  \n",
    "1. (c) $w(t) = w(t-1) + y(t-1)x(t-1)$, take squared norm on $w(t)$ we have \n",
    "\n",
    "\\begin{align*}\n",
    "||w(t)||^2 &= \\left(w(t-1) + y(t-1)x(t-1)\\right)^T\\left(w(t-1) + y(t-1)x(t-1)\\right)\\\\\n",
    "&= ||w(t-1)||^2 + ||y(t-1)||^2||x(t-1)||^2 + 2y(t-1)w^T(t-1)x(t-1) \\\\\n",
    "&= ||w(t-1)||^2 + ||x(t-1)||^2 + 2y(t-1)w^T(t-1)x(t-1) \\\\\n",
    "&\\le ||w(t-1)||^2 + ||x(t-1)||^2\n",
    "\\end{align*}\n",
    "\n",
    "since $y(t-1)w^T(t-1)x(t-1) \\le 0$ because $x(t-1)$ was misclassified by $w(t-1)$.\n",
    "\n",
    "1. (d) Let's use induction.\n",
    "  * When $t=0$, it's obvious that $||w(0)||^2 = 0 \\le tR^2 = 0$.\n",
    "  * Assume at $t$, we have $||w(t)||^2 \\le tR^2$, then at $t+1$, we have $||w(t)||^2 \\le ||w(t-1)||^2 + ||x(t-1)||^2 $ from previous problem. Then we have\n",
    "  \n",
    "  $||w(t)||^2 \\le ||w(t-1)||^2 + ||x(t-1)||^2 \\le (t-1)R^2 + R^2 = tR^2$ \n",
    "  \n",
    "  where we used the fact that $||x(t-1)||^2 \\le R^2$ by definition of $R$.\n",
    "  \n",
    "1. (e) Apply the results from (b) and (d) we have \n",
    "\n",
    "$\\frac{w^T(t)}{||w(t)||} w^* \\ge \\frac{t\\rho}{||w(t)||} \\ge  \\frac{t\\rho}{\\sqrt{t}R} = \\sqrt{t}\\frac{\\rho}{R}$.\n",
    "\n",
    "\n",
    "Reverse the inequality and square, we have \n",
    "\n",
    "\\begin{align*}\n",
    "t &\\le \\frac{R^2}{\\rho^2} \\frac{\\left(w^T(t)w^*\\right)^T\\left(w^T(t)w^*\\right)}{||w(t)||^2} \\\\\n",
    "&= \\frac{R^2}{\\rho^2} \\frac{w^{*T}w(t)w^T(t)w^*}{||w(t)||^2} \\\\\n",
    "&= \\frac{R^2}{\\rho^2} ||w^*||^2\n",
    "\\end{align*}\n",
    "\n",
    "Or we can use the hint, where \n",
    "$\\frac{w^{*T}w^*}{||w(t)||||w^*||} \\le 1$ because $||w^T(t)w^*|| \\le ||w^T(t)||\\cdot||w^*||$ \n",
    "\n",
    "according to the Cauchy-Schwarz inequality. Then we have \n",
    "\n",
    "$\\sqrt{t}\\frac{\\rho}{R} \\le \\frac{w^{*T}w^*}{||w(t)||} \\le ||w^*||$\n",
    "\n",
    "Move $t$ to the right and square, we obtain the desired inequality."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.4\n",
    "\n",
    "1. (a) See plot below\n",
    "1. (b) It takes about tens of iterations to find a line that can separate the data, very fast. But the final hypothesis $g$ is not necessarily close the target functio $f$.\n",
    "1. (c) Repeat the experiment in (b) shows similar results\n",
    "1. (d) When $N=100$, the PLA still finds a solution fast in about 100 iterations. It can be much slower on some data.\n",
    "1. (e) $N=1000$, it now takes more about 1000 iterations to find a solution\n",
    "1. (f) $N=1000$ and $d=10$, it usually takes thousands of iterations to find a solution. \n",
    "1. (g) See graph below.\n",
    "1. (h) As $N$ or $d$ increases, it takes more time to find a solution. The maximum number of updates are approximately on the order of $Nd$. As long as the data are separable, it can always find a solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### problem 1.4 (a)-(c)\n",
    "lb, ub = -100, 100\n",
    "N, dim = 20, 2 \n",
    "num_grid_points = 2000\n",
    "coeff_lb, coeff_ub = -10, 10\n",
    "eta = 1\n",
    "maxit = 100\n",
    "use_adaline, randomize =False, False\n",
    "_, _, _ = run_perceptron_experiment(N, dim, lb, ub, num_grid_points,\n",
    "                             coeff_lb, coeff_ub, eta, maxit, use_adaline, randomize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### problem 1.4 (d)(e)\n",
    "lb, ub = -100, 100\n",
    "N, dim = 1000, 2\n",
    "num_grid_points = 2000\n",
    "coeff_lb, coeff_ub = -10, 10\n",
    "eta = 1\n",
    "maxit = 2000\n",
    "use_adaline, randomize =False, False\n",
    "_, _, _ = run_perceptron_experiment(N, dim, lb, ub, num_grid_points,\n",
    "                             coeff_lb, coeff_ub, eta, maxit, use_adaline, randomize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### problem 1.4 (f)\n",
    "lb, ub = -100, 100\n",
    "N, dim = 1000, 10 \n",
    "num_grid_points = 2000\n",
    "coeff_lb, coeff_ub = -10, 10\n",
    "eta = 1\n",
    "maxit = 50000\n",
    "use_adaline, randomize =False, False\n",
    "_, _, _ = run_perceptron_experiment(N, dim, lb, ub, num_grid_points,\n",
    "                                 coeff_lb, coeff_ub, eta, maxit, use_adaline, randomize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### problem 1.4 (g)\n",
    "lb, ub = -100, 100\n",
    "N, dim = 1000, 10 \n",
    "num_grid_points = 2000\n",
    "coeff_lb, coeff_ub = -10, 10\n",
    "eta = 1\n",
    "maxit = 50000\n",
    "use_adaline, randomize =False, True\n",
    "show_plot = False\n",
    "num_iterations = []\n",
    "for it in range(100):\n",
    "    #print('Working on experiment: ', it)\n",
    "    num_it, _, _ = run_perceptron_experiment(N, dim, lb, ub, num_grid_points,\n",
    "                                     coeff_lb, coeff_ub, eta, maxit, use_adaline, randomize,\n",
    "                                      show_plot)\n",
    "    num_iterations.append(num_it)\n",
    "    \n",
    "plt.hist(num_iterations)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.5:The perceptron learning algorithm works like this: In each iteration $t$, pick a random $\\left(x\\left(t\\right), y\\left(t\\right)\\right)$ and compute the 'signal' $s(t) = w^{T}(t)x(t)$. If $y(t) \\cdot s(t)\\le 0$, update $w$ by \n",
    "#### $w\\left(t + 1\\right) \\gets w\\left(t\\right) + y\\left(t\\right) \\cdot x\\left(t\\right)$;\n",
    "#### One may argue that this algorithm does not take the 'closeness' between $s(t)$ and $y(t)$ into consideration. Let's look at another perceptron learning algorithm: In each iteration, pick a random $\\left(x\\left(t\\right), y\\left(t\\right)\\right)$ and compute $s(t)$. If $y(t) \\cdot s(t)\\le 1$ , update $w$ by \n",
    "#### $w\\left(t + 1\\right) \\gets w\\left(t\\right) + \\eta \\cdot \\left( y\\left(t\\right) \\cdot s\\left(t\\right) \\right) \\cdot x\\left(t\\right)$,\n",
    "#### where $\\eta$ is a constant. That is, if $s(t)$ agrees with $y(t)$ well (their product is $> 1$), the algorithm does nothing. On the other hand, if $s(t)$ is further from $y(t)$, the algorithm changes $w(t)$ more. In this problem, you are asked to implement this algorithm and study its performance.\n",
    "\n",
    "**(a) Generate a training data set of size $100$ similar to that used in Exercise 1.4.\n",
    "Generate a test data set of size $10000$ from the same process. To get g, run the algorithm above with $\\eta = 100$ on the training data set, until a maximum of $1000$ updates has been reached. Plot the training data set, the target function $f$, and the final hypothesis g on the same figure.\n",
    "Report the error on the test set.**\n",
    "\n",
    "**(b) Use the data set in (a) and redo everything with $\\eta = 1$.**\n",
    "- Check the code's output\n",
    "\n",
    "**(c) Use the data set in (a) and redo everything with $\\eta = 0.01$.**\n",
    "- Check the code's output\n",
    "\n",
    "**(d) Use the data set in (a) and redo everything with $\\eta = 0.0001$.**\n",
    "- Check the code's output\n",
    "\n",
    "**(e) Compare the results that you get from (a) to (d).**\n",
    "- When $\\eta$ is large, with the same number of updates, the Adaline algorithm may have difficulty finding a solution (overshoot), and thus have lower accuracy. When $\\eta$ is small, the algorithm can find a solution and have much better accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Problem 1.5 (a)-(d)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a random target function\n",
    "def generate_target_function():\n",
    "    p1, p2 = np.random.uniform(-10, 10, (2, 2))\n",
    "    slope = (p2[1] - p1[1]) / (p2[0] - p1[0])\n",
    "    intercept = p1[1] - slope * p1[0]\n",
    "    return slope, intercept\n",
    "\n",
    "slope, intercept = generate_target_function()\n",
    "def target_function(x):\n",
    "    return slope * x + intercept\n",
    "\n",
    "# Generate datasets\n",
    "def generate_data(num_points):\n",
    "    X = np.random.uniform(-10, 10, (num_points, 2))\n",
    "    Y = np.where(X[:, 1] > target_function(X[:, 0]), 1, -1)\n",
    "    return X, Y\n",
    "\n",
    "# Modified Perceptron Learning Algorithm\n",
    "def perceptron(X, Y, eta, max_iterations=1000, clip_threshold=1e5):\n",
    "    weights = np.random.randn(3) * 0.01  # Small random initialization\n",
    "    iteration = 0\n",
    "    while iteration < max_iterations:\n",
    "        # Check for large weights and clip them\n",
    "        weights = np.clip(weights, -clip_threshold, clip_threshold)\n",
    "        \n",
    "        idx = np.random.choice(X.shape[0])\n",
    "        x, y = X[idx], Y[idx]\n",
    "        signal = np.dot(weights, [1, x[0], x[1]])\n",
    "        \n",
    "        if y * signal <= 1:\n",
    "            weight_update = eta * (y - signal) * np.array([1, x[0], x[1]])\n",
    "            if np.isnan(weight_update).any() or np.isinf(weight_update).any():\n",
    "                print(\"Warning: Weight update is NaN or Inf!\")\n",
    "                print(\"x:\", x)\n",
    "                print(\"y:\", y)\n",
    "                print(\"signal:\", signal)\n",
    "                print(\"weights:\", weights)\n",
    "                break  # Terminate training if NaN or Inf values are detected\n",
    "            \n",
    "            weights += weight_update\n",
    "            iteration += 1\n",
    "    return weights\n",
    "\n",
    "# Visualization\n",
    "def visualize(X, Y, weights, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot data points\n",
    "    plt.scatter(X[Y == 1][:, 0], X[Y == 1][:, 1], color='blue', marker='o', label='Class 1')\n",
    "    plt.scatter(X[Y == -1][:, 0], X[Y == -1][:, 1], color='red', marker='x', label='Class -1')\n",
    "    \n",
    "    # Plot target function (f)\n",
    "    x = np.linspace(-10, 10, 400)\n",
    "    y = target_function(x)\n",
    "    plt.plot(x, y, 'green', label='Target function (f)')\n",
    "    \n",
    "    # Plot hypothesis (g)\n",
    "    y_g = -(weights[0] + weights[1]*x) / weights[2]\n",
    "    plt.plot(x, y_g, 'black', linestyle='--', label='Hypothesis (g)')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"x-axis\")\n",
    "    plt.ylabel(\"y-axis\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(weights, X_test, Y_test):\n",
    "    predictions = np.sign(np.dot(np.column_stack((np.ones(X_test.shape[0]), X_test)), weights))\n",
    "    return np.mean(predictions != Y_test)\n",
    "\n",
    "# Normalization function\n",
    "def normalize_data(X):\n",
    "    X_mean = np.mean(X, axis=0)\n",
    "    X_std = np.std(X, axis=0)\n",
    "    X_normalized = (X - X_mean) / X_std\n",
    "    return X_normalized, X_mean, X_std\n",
    "\n",
    "# Main execution for different values of eta\n",
    "etas = [100, 1, 0.01, 0.0001]\n",
    "train_X, train_Y = generate_data(100)\n",
    "\n",
    "# Normalize the training data\n",
    "train_X_normalized, X_mean, X_std = normalize_data(train_X)\n",
    "\n",
    "test_X, test_Y = generate_data(10000)\n",
    "# Normalize the test data\n",
    "test_X_normalized = (test_X - X_mean) / X_std\n",
    "\n",
    "for eta in etas:\n",
    "    weights = perceptron(train_X_normalized, train_Y, eta)\n",
    "    visualize(train_X, train_Y, weights, title=f\"PLA with η = {eta}\")\n",
    "    error = evaluate(weights, test_X_normalized, test_Y)\n",
    "    print(f\"Error on test set for η = {eta}: {error}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.6: Consider a sample of $10$ marbles drawn independently from a bin that holds red and green marbles. The probability of a red marble is $\\mu$. For $\\mu=0.05$, $\\mu=0.5$, and $\\mu=0.8$, compute the probability of getting no red marbles $\\left( \\nu=0 \\right)$ in the following cases.\n",
    "\n",
    "**(a) We draw only one such sample. Compute the probability that $\\nu=0$.**\n",
    "- $P(\\nu=0) = (1-\\mu)^{10}$, so \n",
    "    * $P(\\nu = 0) =  0.5987369392383787$ when $\\mu = 0.05$\n",
    "    * $P(\\nu = 0) =  0.0009765625$ when $\\mu = 0.5$\n",
    "    * $P(\\nu = 0) =  1.0239999999999978e-07$ when $\\mu = 0.8$\n",
    "\n",
    "**( b) We draw $1,000$ independent samples. Compute the probability that (at least) one of the samples has $\\nu=0$.**\n",
    "- We compute the probability that none of the 1000 samples have $\\nu = 0$, i.e. all samples have $\\nu \\gt 0$. For a given sample, we have $P(\\nu \\gt 0) = 1-P(\\nu = 0) = 1-(1-\\mu)^{10}$.  \n",
    "- For all 1000 samples to have $\\nu \\gt 0$, the probability is $P(\\cap_{i=1}^{1000} \\nu_{i} \\gt 0) = \\prod_{i=1}^{1000}P(\\nu_i \\gt 0) = \\prod_{i=1}^{1000}[1-(1-\\mu)^{10}] =[1-(1-\\mu)^{10}]^{1000}$\n",
    "- So the probability that at least one of the samples has $\\nu = 0$ is: $1-P(\\cap_{i=1}^{1000} \\nu_{i} \\gt 0) = 1-[1-(1-\\mu)^{10}]^{1000}$\n",
    "    * $P = 1$ when $\\mu = 0.05$\n",
    "    * $P = 0.623576201943276$ when $\\mu = 0.5$\n",
    "    * $P = 0.00010239476257623004$ when $\\mu = 0.8$\n",
    "\n",
    "**(c) Repeat (b) for 1,000,000 independent samples.**\n",
    "- For 1000000 samples, we have the probability: $1-P(\\cap_{i=1}^{1000000} \\nu_{i} \\gt 0) = 1-[1-(1-\\mu)^{10}]^{1000000}$\n",
    "    * $P = 1$ when $\\mu = 0.05$\n",
    "    * $P = 1$ when $\\mu = 0.5$\n",
    "    * $P = 0.09733159268316072$ when $\\mu = 0.8$\n",
    "\n",
    "According to Hoeffding inequality, for given tolerance, the upper bound decreases with the number of samples. The probability of the deviation between $\\mu$ and $\\nu'$ (proportion of red marbles in samples) becomes smaller and smaller. So $\\nu'$ is closer to $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Problem 1.7: A sample of heads and tails is created by tossing a coin a number of times independently. Assume we have a number of coins that generate different samples independently. For a given coin, let the probability of heads (probability of error) be $\\mu$. The probability of obtaining $k$ heads in $N$ tosses of this coin is given by the binomial distribution:\n",
    "#### $P\\left[ k \\mid N,\\mu \\right]=\\binom{N}{k}\\mu^{k}\\left( 1-\\mu \\right)^{N-k}$\n",
    "#### Remember that the training error $\\nu$ is $\\frac{k}{N}$\n",
    "\n",
    "**(a) Assume the sample size $(N)$ is $10$ . I fall the coins have $\\mu=0.05$ compute the probability that at least one coin will have $\\nu=0$ for the case of $1$ coin, $1,000$ coins, $1,000,000$ coins. Repeat for $\\mu=0.8$.**\n",
    "- Suppose there are $m$ coins, we compute the probability that none of the coins have $\\nu = 0$, i.e. all coins have $\\nu \\gt 0$. For a given coin, we have $P(\\nu \\gt 0) = 1-P(\\nu = 0) = 1-P[0|N,\\mu] = 1-(1-\\mu)^N$.  \n",
    "For all $m$ coins to have $\\nu \\gt 0$, the probability is $P(\\cap_{i=1}^{m} \\nu_{i} \\gt 0) = \\prod_{i=1}^{m}P(\\nu_i \\gt 0) = \\prod_{i=1}^{m}[1-(1-\\mu)^{N}] =[1-(1-\\mu)^{N}]^{m}$\n",
    "- So the probability that at least one of the coins has $\\nu = 0$ is: $1-P(\\cap_{i=1}^{m} \\nu_{i} \\gt 0) = 1-[1-(1-\\mu)^{N}]^{m}$\n",
    "    * $P= 0.5987369392383787$ when $\\mu = 0.05, m = 1$\n",
    "    * $P= 1$ when $\\mu = 0.05, m = 1000$\n",
    "    * $P= 1$ when $\\mu = 0.05, m = 1000000$\n",
    "  \n",
    "    * $P= 1.02400000034919e-07$ when $\\mu = 0.8, m = 1$\n",
    "    * $P= 0.00010239476257623004$ when $\\mu = 0.8, m = 1000$\n",
    "    * $P= 0.09733159268316072$ when $\\mu = 0.8, m = 1000000$  \n",
    "\n",
    "\n",
    "**(b) For the case $N=6$ and $2$ coins with $\\mu=0.5$ for both coins, plot the probability $P\\left[\\max_{i}\\left|\\nu_{i}-\\mu_{i}\\right|\\gt \\epsilon\\right]$ for $\\epsilon$ in the range $\\left[0,1\\right]$ (the max is over coins). On the same plot show the bound that would be obtained using the Hoeffding Inequality. Remember that for a single coin, the Hoeffding bound is $P\\left[\\left|\\nu-\\mu\\right|\\gt \\epsilon\\right]\\le 2\\mathcal{e}^{-2N\\epsilon^{2}}$.**\n",
    "**[Hint: Use $\\begin{matrix} P\\left[A\\:or\\:B\\right]=P\\left[A\\right]+P\\left[B\\right] & P\\left[A\\:or\\:B\\right]=P\\left[A\\right]+P\\left[B\\right]-P\\left[A\\right]\\cdot P\\left[B\\right] \\end{matrix}$, where the last equality follows by independence, to evaluate $P\\left[max\\:...\\right]$]**\n",
    "- For $N=6$ and 2 coins with $\\mu = 0.5$, we have \\begin{align*}\n",
    "P[max_{i}|\\nu_i - \\mu| \\gt \\epsilon] &= 1 - P[max_{i}|\\nu_i - \\mu| \\le \\epsilon]\\\\\n",
    "&= 1 - P[|\\nu_1 - \\mu| \\le \\epsilon\\;and\\;|\\nu_2 - \\mu| \\le \\epsilon\\;\\dots\\;and\\;|\\nu_N - \\mu| \\le \\epsilon]\\\\\n",
    "&= 1 - \\prod_{i=1}^{N}P[|\\nu_i - \\mu| \\le \\epsilon]\\\\\n",
    "&= 1 - P[|\\nu_1 - \\mu| \\le \\epsilon]^N\\\\\n",
    "\\end{align*}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.8 \n",
    "\n",
    "1. (a) Consider random variable $I(t\\ge \\alpha)$, which equals to $1$ when $t\\ge \\alpha$, else $0$. It's clear that for $\\alpha \\gt 0$ and $t$ a non-negative random variable, we have $\\alpha I(t \\ge \\alpha) \\le t$, take expectation on both sides, and since expectation is a monotonically increasing function here $(t \\ge 0)$ , we have \n",
    "\n",
    "\\begin{align*}\n",
    "E[\\alpha I(t \\ge \\alpha)] &\\le E[t]\\\\\n",
    "\\alpha E[I(t \\ge \\alpha)] &\\le E[t]\\\\\n",
    "E[I(t \\ge \\alpha)] &\\le \\frac{E[t]}{\\alpha}\\\\\n",
    "P[t \\ge \\alpha] &\\le \\frac{E[t]}{\\alpha}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "1. (b) Since $(u-\\mu)^2 \\ge 0$, according to problem (a) above, for any $\\alpha \\gt 0$, we have $P[(u - \\mu)^2 \\ge \\alpha] \\le \\frac{E[(u-\\mu)^2]}{\\alpha} = \\frac{\\sigma^2}{\\alpha}$.\n",
    "\n",
    "1. (c) $u = \\frac{1}{N}\\sum_{n=1}^{N}$, this random variable has mean $\\mu$ and variance $\\frac{\\sigma^2}{N}$. Take this into problem (b)'s inequation, we have $P[(u-\\mu)^2 \\ge \\alpha] \\le \\frac{\\sigma^2}{N\\alpha}$.\n",
    "\n",
    "This is the Chebyshev Inequality. Notice that the RHS goes down linearly in $N$, while the counterpart in Hoeffding's Inequality goes down exponentially. \n",
    "\n",
    "#### Problem 1.9\n",
    "\n",
    "1. (a) Consider random variable $I(t\\ge \\alpha)$, which equals to $1$ when $t\\ge \\alpha$, else $0$. It's clear that $e^{st}$ is monotonically increasing in $t$.We have $e^{\\alpha t} I(t \\ge \\alpha) \\le e^{st}$, take expectation on both sides, and since expectation is a monotonically increasing function here $(e^{st} \\ge 0)$ , we have \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "E[e^{\\alpha t} I(t \\ge \\alpha)] &\\le E[e^{st}]\\\\\n",
    "e^{\\alpha t} E[I(t \\ge \\alpha)] &\\le E[e^{st}]\\\\\n",
    "E[I(t \\ge \\alpha)] &\\le e^{-\\alpha t}E[e^{st}]\\\\\n",
    "P[t \\ge \\alpha] &\\le e^{-\\alpha t}T(s)\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "1. (b) Choose $t = uN$, and use $N\\alpha$ to replace $\\alpha$, according the previous problem, we have\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P[uN \\ge N\\alpha] &\\le e^{-sN\\alpha}E[e^{suN}]\\\\\n",
    "P[u \\ge \\alpha] &\\le e^{-sN\\alpha}E[e^{s\\sum_{n=1}^{N}u_n}]\\\\\n",
    "P[u \\ge \\alpha] &\\le e^{-sN\\alpha}E[\\prod_{n=1}^{N}e^{su_n}]\\\\\n",
    "P[u \\ge \\alpha] &\\le e^{-sN\\alpha}\\prod_{n=1}^{N}E[e^{su_n}]\\\\\n",
    "P[u \\ge \\alpha] &\\le e^{-sN\\alpha}E[e^{su_n}]^N\\\\\n",
    "P[u \\ge \\alpha] &\\le \\left(e^{-s\\alpha}U(s)\\right)^N\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "1. (c) $U(s) = E(e^{su_n}) = P(u_n=0)e^0 + P(u_n=1)e^s = \\frac{1}{2}(1+e^s)$, let's minimize $e^{-s\\alpha}U(s)$ by taking its derivative w.r.t. $s$ and let it equal to $0$, we have\n",
    "\n",
    "\\begin{align*}\n",
    "-\\alpha e^{-s\\alpha}\\frac{1}{2}(1+e^s) + e^{-s\\alpha}\\frac{1}{2}e^s &= 0\\\\\n",
    "\\end{align*}\n",
    "\n",
    "we conclude that $s = ln{\\frac{\\alpha}{1-\\alpha}}$ since $0 \\lt \\alpha \\lt 1$.\n",
    "\n",
    "1. (d) It's easy to see that $E[u] = \\frac{1}{2}$. Let $\\alpha = E(u) + \\epsilon = \\frac{1}{2} + \\epsilon$, then we have $P[u \\ge E(u) + \\epsilon] \\le (e^{-s\\alpha}U(s))^N$ from previous problem. Since this inequality holds for every $s \\gt 0$, it also holds for $s = ln{\\frac{\\alpha}{1-\\alpha}}$. Take this $s$ into the RHS of the inequality, we have\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "e^{-s\\alpha}U(s) &= e^{-s\\alpha} \\frac{1}{2}(1+e^s)\\\\\n",
    "&= \\frac{1}{2} e^{-\\alpha ln{\\frac{\\alpha}{1-\\alpha}}} (1+e^ {ln{\\frac{\\alpha}{1-\\alpha}}})\\\\\n",
    "&= \\frac{1}{2} \\left(\\frac{1-\\alpha}{\\alpha}\\right)^{\\alpha} (1+\\frac{\\alpha}{1-\\alpha})\\\\\n",
    "&= \\frac{1}{2} \\left(\\frac{1-\\alpha}{\\alpha}\\right)^{\\alpha} \\frac{1}{1-\\alpha}\\\\\n",
    "&= \\frac{1}{2} \\frac{(1-\\alpha)^{\\alpha -1}}{\\alpha^{\\alpha}}\\\\\n",
    "&= \\frac{1}{2} \\frac{(\\frac{1}{2}-\\epsilon)^{\\epsilon -\\frac{1}{2}}}{(\\frac{1}{2}+\\epsilon)^{\\frac{1}{2}+\\epsilon}}\\\\\n",
    "&= \\frac{1}{2}(\\frac{1}{2}-\\epsilon)^{-(\\frac{1}{2}-\\epsilon)}(\\frac{1}{2}+\\epsilon)^{-(\\frac{1}{2}+\\epsilon)}\\\\\n",
    "&= 2^{-\\beta}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $\\beta = 1 + (\\frac{1}{2}+\\epsilon)log_2{(\\frac{1}{2}+\\epsilon)}+ (\\frac{1}{2}-\\epsilon)log_2{(\\frac{1}{2}-\\epsilon)}$\n",
    "\n",
    "This proves that $P[u \\ge E(u) + \\epsilon] \\le 2^{-\\beta N}$.\n",
    "\n",
    "We now prove that $\\beta \\gt 0$. To prove that $\\beta \\gt 0$, we first prove that $\\beta$ is mononically increasing, then we find its minimum at $\\epsilon = 0$. \n",
    "\n",
    "Take derivative of $\\beta$ with respect to $\\epsilon$, we have \n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial{\\beta}}{\\partial{\\epsilon}} &= log_2{(\\frac{1}{2}+\\epsilon)} + 1 - log_2{(\\frac{1}{2}-\\epsilon)} - 1\\\\\n",
    "&= log_2{(\\frac{1}{2}+\\epsilon)} - log_2{(\\frac{1}{2}-\\epsilon)}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "The derivative is always larger or equal to zero, so $\\beta$ is mononically increasing function. It thus achieves minimum at left point, $\\epsilon=0$, where $\\beta=0$. \n",
    "So we have proved that $\\beta \\gt 0$, since $0 \\lt \\epsilon \\lt \\frac{1}{2}$. hence the bound is exponentially decreasing in $N$.\n",
    "\n",
    "#### Problem 1.10\n",
    "\n",
    "1. (a) $E_{off}(h,f)$ equals to the fraction of odd numbers between $N+1$ and $N+M$ in total $M$ numbers.\n",
    "\n",
    "1. (b) For a function $f$ to generate $\\mathcal{D}$ in a noiseless setting, it means $f(x_i)=y_i$ for $i=1,2,\\dots, N$. They only have freedom to assign various values on the rest points in $\\mathcal{X}$, i.e. $x_{N+1},\\dots,x_{N+M}$. So there are total $2^M$ $f$ that can generate $\\mathcal{D}$.\n",
    "\n",
    "1. (c) Among those $f$ in(b), if they agree with a given $h$ on $M-k$ points, i.e. $E_{off}(h,f)=\\frac{k}{M}$, then each of them need to choose $k$ points from $M$ $x_{N+1},\\dots,x_{N+M}$ to match with $y$, and other $M-k$ points to mismatch with $y$.\n",
    "This has ${M \\choose k}$ combinations.\n",
    "\n",
    "1. (d) The expectation is w.r.t. $f$. Given a hypothesis $h$, for an integer $k$ between $0$ and $M$, from previous problem (c), we know that there are ${M \\choose k}$ number of functions $f$ that satisfy $E_{off}(h,f)=\\frac{k}{M}$. So the probability to get $E_{off}(h,f)=\\frac{k}{M}$ is $\\frac{M \\choose k }{2^M}$. So the expectation is $E_{f}[E_{off}(h,f)] = \\frac{1}{2^M} \\sum_{k=0}^{M} {M \\choose k} \\frac{k}{M}$.\n",
    "\n",
    "1. (e) The above expectation in problem (d) depends on $M$ only, and doesn't depend on $h$ at all (each term in the expectation depends on the number of mismatches between $h$ and $f$, but they are consumed in the expectation). So for any two deterministic algorithms $A_1$ and $A_2$, the expectations will be the same.  \n",
    "\n",
    "We thus proved that in a noiseless setting, for a fixed $\\mathcal{D}$, if all possible $f$ are equally likely, any two deterministic algorithms are equivalent in terms of the expected off-training-set error. \n",
    "\n",
    "#### Problem 1.11\n",
    "\n",
    "* Let the risk to be $r_{1}$ when $y_n=1$ and $r_{-1}$ when $y_n = -1$. The in-sample error $E_{in} = \\sum_{i=1}^{N} max\\left( -h(x_i)y_i,0\\right)r(y_i) = \\sum_{i=1}^{N} max\\left( -h(x_i)y_i,0\\right) [max(y_i,0), max(-y_i,0)] \\cdot [r_1, r_{-1}]^T $\n",
    "\n",
    "#### Problem 1.12\n",
    "\n",
    "1. (a) Take derivative of $E_{in}(h)$ w.r.t. $h$, and let it equal to $0$, we have\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial{E_{in}(h)}}{\\partial{h}} &= \\sum_{n=1}^{N}2(h-y_n) \\\\\n",
    "h_{mean} &= \\frac{1}{N} \\sum_{n=1}^{N}y_n\\\\\n",
    "\\end{align*}\n",
    "\n",
    "1. (b) Take derivative of $E_{in}(h)$ w.r.t. $h$, and let it equal to $0$, we have\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial{E_{in}(h)}}{\\partial{h}} &= \\sum_{n=1}^{N}sign(h - y_n) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "It's clear, that $h_{med}$ (which is any value for which half the data points are at most $h_{med}$ and half the data points are at least $h_{med}$) will make the derivative to zero, thus minimize the in-sample error.\n",
    "\n",
    "1. (c) If $y_N$ is perturbed to $y_N + \\epsilon$, where $\\epsilon \\to \\infty$, we can see that $h_{mean}$ will increase a lot since $y_N$ contributes to its calculation, but $h_{med}$ can stay the same, because it only requires $h_{med} \\lt y_N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
